# LLMs Tool
![Authour](https://img.shields.io/badge/Author-StanleyLsx-red.svg) 
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
![python_version](https://img.shields.io/badge/Python-3.10%2B-green.svg)
[![torch_version](https://img.shields.io/badge/torch-2.0%2B-pink.svg)](requirements.txt)


## Introduction
ä¸€ä¸ªåŸºäºğŸ¤—[HuggingFace](https://huggingface.co/)å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒã€æµ‹è¯•å·¥å…·ã€‚æ”¯æŒä¸åŒæ¨¡å‹çš„webuiã€ç»ˆç«¯é¢„æµ‹ï¼Œæ”¯æŒå„æ¨¡å‹çš„ä½å‚æ•°é‡åŠå…¨å‚æ•°æ¨¡å‹è®­ç»ƒå’Œèåˆï¼ŒRLHFçš„ä»£ç å·¥ä½œè¿˜åœ¨è¿›è¡Œä¸­ã€‚  
ä½œè€…ä¹ æƒ¯äºæŠŠé…ç½®å’Œè¦åšçš„äº‹æƒ…éƒ½å†™åœ¨ä¸€ä¸ªé…ç½®æ–‡ä»¶é‡Œé¢ï¼Œç„¶åä»¥ä¸€ä¸ªä¸»å‡½æ•°ä½œä¸ºå…¥å£ç›´æ¥è¿è¡Œï¼Œæ‰€ä»¥æ‰æœ‰äº†è¿™ä¸ªé¡¹ç›®ã€‚


## Updates
Date| Detail
:---|---
2023-07-25|åˆå§‹ä»“åº“
2023-08-08|å¥–åŠ±æ¨¡å‹è®­ç»ƒ

## Requirement
å‡ ä¸ªé‡è¦ç¯å¢ƒï¼š
* pythonï¼š3.10+  
* torchï¼š2.0.1+  
* peftï¼š0.4.0ï¼ˆè¯¥ç‰ˆæœ¬å·²æ”¯æŒé‡åŒ–4bitä¸‹çš„lora/adaloraè®­ç»ƒï¼‰
* accelerateï¼š0.21.0+
* bitsandbytesï¼šä¸åŒæ“ä½œç³»ç»Ÿä¸‹éœ€è¦å¯¹åº”å®‰è£…ä¸åŒçš„åŒ…ï¼ˆLinuxä¸‹0.39.0+ï¼ŒWindowsä¸‹è¦ä¸“é—¨ä¸‹è½½å¯¹åº”çš„wheelæœ¬åœ°å®‰è£…ï¼‰

å…¶å®ƒç¯å¢ƒè§requirements.txt

## Feature

### Supported models
å¤§æ¨¡å‹ç»è¿‡SFT(ç„¶ååšRLHF)ä¹‹åå¯ç”¨äºå¯¹è¯ä»»åŠ¡Chatï¼Œé¢ä¸–çš„Chatå¤§éƒ¨åˆ†éƒ½æ²¡æœ‰é‡æ–°è®­ç»ƒåŸºåº§ï¼Œæˆ–è€…æ˜¯åŸºäºåŒæ ·çš„åŸºåº§ç»“æ„ç”¨æ•°æ®é‡æ–°é¢„è®­ç»ƒäº†ä¸€ä¸ªåŸºåº§ï¼Œä¸‹è¡¨æ˜¯éªŒè¯è¿‡çš„è¢«æ­¤é¡¹ç›®æ”¯æŒçš„åŸºåº§ï¼Œç›¸åº”çš„ä¹Ÿæ”¯æŒåŒæ ·ç»“æ„çš„è¡ç”Ÿå’ŒChatæ¨¡å‹ã€‚

Model   | Scale        | Series
:-------|--------------|--------
ChatGLM1| 6B           |[chatglm1](https://huggingface.co/THUDM/chatglm-6b)
ChatGLM2| 6B           |[chatglm2](https://huggingface.co/THUDM/chatglm2-6bb)
Qwen    | 7B           |[Qwen](https://huggingface.co/Qwen)
Bloom   | 560Mã€9Bã€7B1M |[bloom](https://huggingface.co/bigscience/bloom)ã€[bloomz](https://huggingface.co/bigscience/bloomz)
LLama1  | 3Bã€7Bã€13B    |[openllama](https://huggingface.co/openlm-research)ã€[chinese-alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)ã€[ziya](https://huggingface.co/IDEA-CCNL)
LLama2  | 7Bã€13B       |[llama2](https://huggingface.co/meta-llama)
Baichuan| 7Bã€13B       |[baichuan](https://huggingface.co/baichuan-inc)
Falcon  | 7B           |[falcon](https://huggingface.co/tiiuae/falcon-7b)ã€[chinese-Falcon](https://huggingface.co/Linly-AI)
Aquila  | 7B           |[aquila](https://huggingface.co/BAAI)
InternLM| 7B           |[internlm](https://huggingface.co/internlm)
MOSS    | 16B          |[MOSS](https://huggingface.co/fnlp)
RWKV    | 3Bã€7B        |[rwkv-4-raven](https://huggingface.co/BlinkDL/rwkv-4-raven)

* ä½¿ç”¨RWKVæ—¶å€™éœ€è¦ä½¿ç”¨æœ¬é¡¹ç›®çš„[convert_rwkv_to_hf](engines/utils/convert_rwkv_to_hf.py)æˆ–è€…transformersè‡ªå¸¦çš„[convert_rwkv_checkpoint_to_hf](https://github.com/huggingface/transformers/blob/main/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py)å°†æ¨¡å‹è½¬æˆhfæ ¼å¼ã€‚
* æœªè¿›å…¥ä¸‹è¡¨çš„æ¨¡å‹æˆ–å‚æ•°è§„æ¨¡æš‚æ—¶æ²¡æœ‰ä½¿ç”¨è¯¥é¡¹ç›®è·‘è¿‡ã€‚

### Training methods  

Method        |Supported| 
:-------------|---------|
Full Parameter| âœ…     |
Lora          | âœ…     |
AdaLora       | âœ…     |
QLora         | âœ…     |
Prompt Tuning | âœ…     |
P Tuning      | âœ…     |
Prefix Tuning | âœ…     |

* ä½¿ç”¨Loraå’ŒAdaLoraéƒ½æ”¯æŒQLoraè®­ç»ƒï¼Œä½†æ˜¯é‡åŒ–æ–¹å¼éœ€è¦é€‰æ‹©åŸºäºbitsandbytesçš„bnbé‡åŒ–æ–¹å¼ï¼Œå¯æ”¯æŒ4bitå’Œ8bité‡åŒ–è®­ç»ƒï¼Œå› ä¸ºPeftåœ¨0.4.0ç‰ˆæœ¬åé›†æˆäº†è¯¥é‡åŒ–æ–¹å¼çš„æ¨¡å‹åŠ è½½ï¼Œå¯ä»¥ç›´æ¥é‡åŒ–åè®­ç»ƒã€‚

### Quantization

ä¸¤ç§é‡åŒ–æ–¹å¼åˆ†åˆ«ä¸ºåŸºäºbitsandbytesçš„bnbå’Œcpm_kernelsç»„ä»¶çš„cpmï¼Œå…¶ä¸­cpmé‡åŒ–è„šæœ¬æ¥è‡ª[quantization.py](https://huggingface.co/THUDM/chatglm2-6b/blob/main/quantization.py)ã€‚

### Metric
è·‘æµ‹è¯•é›†æ—¶ä¼šè¾“å‡ºä¸‹é¢å››ä¸ªå¸¸è§„çš„ç”Ÿæˆæ¨¡å‹è¯„ä¼°ç»“æœï¼Œç»“æœä»…é™å‚è€ƒï¼Œå¤§æ¨¡å‹çš„äº‹å®æ€§è¯„ä¼°ç›®å‰æ²¡æœ‰æ›´å¥½çš„åŠæ³•ï¼Œéƒ½æ˜¯å„ä¸ªæ¨¡å‹å‡ºå“æ–¹æˆ–è¯„æµ‹æœºæ„åœ¨å„ç»´åº¦ä¸Šåˆ¶ä½œæ•°æ®é›†åšè¯„æµ‹ï¼Œç›¸å¯¹æ¯”è¾ƒä¸»è§‚ã€‚   

Metric  |Supported| 
:-------|---------|
Rouge-1 | âœ…     |
Rouge-2 | âœ…     |
Rouge-l | âœ…     |
ppl     | âœ…     |


## Getting start
å¼€å§‹ä¹‹å‰ï¼Œéœ€è¦ç¡®å®šè¯•éªŒçš„æ¨¡å‹ï¼Œå¹¶æŠŠæ•´ä¸ªæ¨¡å‹æ–‡ä»¶ä»huggingfaceä¸Šä¸‹è½½ä¸‹æ¥ï¼Œå®Œæˆä¸¤æ­¥ï¼š
1. åœ¨ModelArgumentsä¸­é…ç½®å¥½model_typeå’Œmodel_pathä¸¤ä¸ªå‚æ•°ï¼Œå¦‚æœé™¤äº†model_pathçš„åŸºåº§æ¨¡å‹å¤–è¿˜æœ‰adapteræ¨¡å‹ï¼Œåˆ™éœ€å°†adapteræ¨¡å‹çš„åœ°å€é…ç½®åˆ°checkpoint_dirä¸­ã€‚

```
model_type: str = field(
    default='internlm',
    metadata={
        # æ¨¡å‹ç±»å‹
        'help': 'Model type.',
        'choices': ['chatglm', 'qwen', 'llama', 'falcon', 'baichuan', 'aquila', 'internlm', 'moss', 'bloom', 'rwkv'],
    }
)
model_path: str = field(
    default='/home/XXXXX/llm_models/internLM/intern-chat-7b',
    metadata={
        # ä»huggingface.co/modelsä¸Šä¸‹è½½çš„æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„è·¯å¾„ã€‚
        'help': 'Local path to pretrained model or model identifier from huggingface.co/models.'
    }
)
checkpoint_dir: Optional[str] = field(
    default=None,
    metadata={
        # ä¿å­˜ä¸‹è½½çš„æˆ–è€…è‡ªå·±è®­ç»ƒçš„adapterå¢é‡æ¨¡å‹çš„åœ°æ–¹ã€‚
        'help': 'Path to save the (delta) model checkpoints as well as the configurations automatically.',
    }
)
```
2. åœ¨DataTrainingArgumentsä¸­ä¿®æ”¹prompt_templateä½¿ç”¨å’Œè¯¥æ¨¡å‹é…å¥—çš„templateï¼Œè¿™ä¸ªtemplateä¸€èˆ¬æ˜¯SFTä¹‹åçš„æ¨¡å‹æ‰ä¼šæœ‰ï¼Œä¸”ä¸è®­ç»ƒè€…æœ‰å…³ã€‚æ‰€ä»¥å¦‚æœè¯¥é¡¹ç›®æœªæä¾›çš„ï¼Œåˆ™éœ€è¦è‡ªå·±ä¿®æ”¹engines/utils/prompt_template.pyæ–‡ä»¶ï¼Œæ·»åŠ æ–°çš„templateã€‚
```
prompt_template: Optional[str] = field(
    default='internlm',
    metadata={
        # é€‰æ‹©å¯¹åº”æ¨¡å‹çš„æ¨¡æ¿promptï¼Œä¸€èˆ¬Chatæ¨¡å‹çš„å‡ºå“æ–¹éƒ½ä¼šæœ‰ä¸€ä¸ªå›ºå®šçš„promptã€‚
        'help': 'Which template to use for constructing prompts in training and inference.'
    }
)
```

### Inference  
æ­¤å¤„æä¾›ä¸¤ç§é¢„æµ‹æ–¹å¼ï¼Œåˆ†åˆ«æ˜¯åŸºäºgradioçš„webUIé¢„æµ‹å’Œç»ˆç«¯é¢„æµ‹ã€‚éœ€è¦åœ¨config.pyä¸­å¯¹åº”ä¿®æ”¹modeï¼Œç„¶åè¿è¡Œmain.pyã€‚  

Mode              | Inference Type | 
:-----------------|----------------|
web_inference     | WebUI          |
terminal_inference| Trminal        |

### SFT training

#### è®­ç»ƒæ•°æ®
æŒ‡ä»¤å¾®è°ƒæ•°æ®å‚è€ƒdatasets/finetune/example/trainä¸‹é¢çš„æ–‡ä»¶ï¼Œæ•°æ®ç”±instructionã€inputã€outputå’Œhistoryå››ä¸ªå­—æ®µç»„æˆã€‚
```
[
  {
    "instruction": "å¥½çš„ï¼Œæˆ‘æƒ³é—®ä¸‹ä½ æ˜¯è°ï¼Ÿ",
    "input": "",
    "output": "æˆ‘æ˜¯ä¸€ä¸ªAIæ¨¡å‹ï¼Œèƒ½å¤Ÿè§£å†³ä½ æå‡ºçš„é—®é¢˜ã€‚",
    "history": [
        "ä½ å¥½å‘€ã€‚",
        "ä½ å¥½ï¼Œè¯·é—®æ‚¨æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ"
      ]
  },
  ...  
]
```
ä½¿ç”¨çš„æ—¶å€™æŠŠæ•°æ®è·¯å¾„å¡«å†™åˆ°DataTrainingArgumentsé…ç½®é‡Œé¢ï¼š
```
train_file_dir: Optional[str] = field(
    default='datasets/finetune/train',
    metadata={
        # è®­ç»ƒé›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The train json data file folder.'
    }
)
validation_file_dir: Optional[str] = field(
    default='datasets/finetune/test',
    metadata={
        # éªŒè¯é›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The evaluation json file folder.'
    }
)
```

#### è®­ç»ƒé…ç½®
éœ€è¦åœ¨config.pyä¸­å¯¹åº”ä¿®æ”¹modeä¸ºtrain_supervised_fine_tuningï¼Œç„¶ååœ¨TrainingArgumentsä¸­é…ç½®å¥½å„é¡¹è®­ç»ƒå‚æ•°ï¼Œç„¶åè¿è¡Œmain.pyã€‚å¸¸ç”¨çš„ä¸€äº›å‚æ•°å¦‚ä¸‹ï¼š

Arguments                    | Describe               | 
:----------------------------|------------------------|
fine_tuning_type             | è®­ç»ƒæ–¹å¼                |
output_dir                   | è®­ç»ƒç»“æœè¾“å‡ºçš„æ–‡ä»¶å¤¹     |
num_train_epochs             | è®­ç»ƒçš„è½®æ¬¡              |
gradient_accumulation_steps  | æ¢¯åº¦ç´¯ç§¯                |
per_device_train_batch_size  | æ¯ä¸ªè®¾å¤‡ä¸Šçš„æ‰¹å¤§å°       |
learning_rate                | å­¦ä¹ ç‡                  |
fp16                         | è®¾ç½®Trueä¸ºå¼€æ··åˆç²¾åº¦è¿ç®— |


* éœ€è¦ä½¿ç”¨deepspeedçš„æ—¶å€™ï¼Œå°†é…ç½®æ–‡ä»¶çš„jsonè·¯å¾„ï¼Œå¡«å†™åˆ°TrainingArgumentsçš„deepspeedå‚æ•°ä¸­ã€‚
* Loraå’Œå…¶å®ƒadapterè®­ç»ƒæ–¹å¼çš„é…ç½®å‚æ•°ä¹Ÿåœ¨TrainingArgumentsä¸­ï¼Œè¿™é‡Œé¢è¦æ³¨æ„lora_targetçš„è®¾ç½®è¦æ ¹æ®è‡ªå·±çš„æ¨¡å‹ç»“æ„æ¥ï¼Œé…ç½®ä¸­ç»™äº†ä¸€äº›å‚è€ƒã€‚
* QLoraåªæ”¯æŒLoraå’ŒAdaLoraä¸¤ç§æ–¹å¼ï¼Œé‡åŒ–æ–¹å¼éœ€è¦é€‰æ‹©bnbï¼Œæ”¯æŒint4å’Œint8ä¸¤ç§é‡åŒ–ã€‚

```
quantization: Optional[str] = field(
    default='bnb',
    metadata={
        # å¦‚æœä½¿ç”¨qloraåªèƒ½é€‰æ‹©bnbï¼Œä¸¤ç§é‡åŒ–æ–¹å¼åŒºåˆ«ä¸å¤§ã€‚
        'help': 'The specific model version to use (can be a branch name, tag name or commit id).',
        'choices': ['cpm', 'bnb'],
    }
)
quantization_bit: Optional[int] = field(
    default=None,
    metadata={
        # ä½¿ç”¨8bité‡åŒ–è¿˜æ˜¯4bité‡åŒ–ï¼Ÿ
        'help': 'The number of bits to quantize the model.',
        'choices': [4, 8],
    }
)
```

### RM training
#### è®­ç»ƒæ•°æ®
æŒ‡ä»¤å¾®è°ƒæ•°æ®å‚è€ƒdatasets/rm/example/trainä¸‹é¢çš„æ–‡ä»¶ï¼Œæ•°æ®ç”±instructionã€inputã€outputä¸‰ä¸ªå­—æ®µç»„æˆã€‚outputæ˜¯ä¸€ä¸ªä¸¤å…ƒç´ åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯é‡‡çº³çš„ç­”æ¡ˆï¼Œç¬¬äºŒä¸ªæ˜¯æ‹’ç»çš„ç­”æ¡ˆã€‚  
ä½¿ç”¨çš„æ—¶å€™æŠŠè®­ç»ƒå¥–åŠ±æ¨¡å‹çš„æ•°æ®SFTé‡Œé¢ä¸€æ ·å¡«å†™åˆ°DataTrainingArgumentsé…ç½®é‡Œé¢ã€‚

#### è®­ç»ƒé…ç½®
éœ€è¦åœ¨config.pyä¸­å¯¹åº”ä¿®æ”¹modeä¸ºtrain_reward_modelï¼Œç„¶ååœ¨TrainingArgumentsä¸­é…ç½®å¥½å„é¡¹è®­ç»ƒå‚æ•°ï¼Œç„¶åè¿è¡Œmain.pyã€‚å¸¸ç”¨çš„å‚æ•°å’ŒSFTä¸€æ ·ï¼Œå‚åŠ ä¸Šé¢çš„SFTè®­ç»ƒé…ç½®å†…å®¹ã€‚

* å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸æ”¯æŒç¬¬ä¸€ä»£ChatGLM6Bï¼Œå› ä¸ºé¡¹ç›®ç”¨trlçš„AutoModelForCausalLMWithValueHeadç»„ä»¶æ˜¯åŸºäºCausalLMæ¨¡å‹çš„ã€‚ChatGLM6Bæ˜¯åŸºäºPrefix LMå®ç°çš„ã€‚

### Test
éœ€è¦åœ¨config.pyä¸­å°†modeä¿®æ”¹ä¸ºbatch_testï¼Œä¿®æ”¹DataTrainingArgumentsä¸­çš„test_fileï¼Œç„¶åè¿è¡Œmain.pyã€‚æ­¤å¤„æä¾›ä¸¤ç§æ–‡ä»¶ç±»å‹çš„æµ‹è¯•æ–¹å¼ï¼ŒåŒºåˆ«å¦‚ä¸‹ï¼š

File Type| Describe                                         | 
:--------|--------------------------------------------------|
json     | éœ€è¦å’Œè®­ç»ƒé›†çš„ç»“æ„ä¿æŒä¸€è‡´ï¼Œä¸”outputå¿…é¡»æœ‰å†…å®¹ï¼Œç»“æœé‡Œä¼šåŒ…å«metricså’Œå¯¹åº”çš„é¢„æµ‹ç»“æœ |
txt      | æŒ‰è¡Œå°†å¾…é¢„æµ‹çš„è¯­å¥æ”¾åˆ°æ–‡ä»¶ä¸­ï¼Œç»“æœåªä¼šè¾“å‡ºå¯¹åº”çš„é¢„æµ‹ç»“æœ                         |

```
test_file: Optional[str] = field(
    default='datasets/finetune/test/test_data.json',
    metadata={
        # æµ‹è¯•é›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The test file.'
    }
)
```

### Others
Mode                | Describe                     | 
:-------------------|------------------------------|
merge_peft_model    | å°†adapteræ¨¡å‹å’ŒåŸºåº§æ¨¡å‹èåˆ    |
show_model_info     | æ‰“å°æ¨¡å‹çš„ç»“æ„å’Œæ¨¡å‹çš„å‚æ•°      |
save_quantized_model| é‡åŒ–å¹¶ä¿å­˜é‡åŒ–æ¨¡å‹             |

* merge_peft_modelå’Œsave_quantized_modeléœ€è¦åœ¨ModelArgumentsè®¾ç½®è¾“å‡ºåœ°å€ã€‚
```
quantized_or_merged_output_dir: Optional[str] = field(
    default=None,
    metadata={
        # å½“ä½ æƒ³ä¿å­˜é‡åŒ–åçš„æ¨¡å‹æˆ–è€…èåˆåçš„æ¨¡å‹æ—¶ï¼Œå¤„ç†åçš„æ¨¡å‹ä¿å­˜çš„åœ°å€ã€‚
        'help': 'Path to save the quantized or merged model checkpoints as well as the configurations manually.',
    }
)
```
* ä½¿ç”¨bnbé‡åŒ–å°†ä¼šé»˜è®¤å¯¹æ‰€æœ‰çº¿æ€§å±‚è¿›è¡Œé‡åŒ–ï¼Œä½¿ç”¨cpmé‡åŒ–åˆ™éœ€è¦åœ¨ModelArgumentsè®¾ç½®ä¸­æ‰‹åŠ¨è®¾ç½®å“ªäº›çº¿æ€§å±‚éœ€è¦é‡åŒ–ã€‚![ct-logo-d2ebd333](https://github.com/StanleyLsx/llms_tool/assets/9429671/c10f7234-480b-4f42-92a4-8acb720aede7)


```
cpm_quantization_target: Optional[str] = field(
    default='query_key_value',
    metadata={
        # éœ€è¦å¯¹è¿™ä¸ªæ¨¡å‹é‡Œé¢çš„å“ªäº›çº¿æ€§å±‚è¿›è¡Œé‡åŒ–ï¼Ÿ
        'help': "Name(s) of target modules to use cpm Quantize. Use comma to separate multiple modules.
    }
)
```

## Todo
- [ ] æ¨¡å‹å¢å¼ºé¢„è®­ç»ƒ
- [ ] PPOæ¨¡å‹è®­ç»ƒ
- [x] å¥–åŠ±æ¨¡å‹è®­ç»ƒ
- [ ] nbceå’Œntké›†æˆ
