# LLMs Tool  
![Authour](https://img.shields.io/badge/Author-stanleylsx-red.svg) 
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
![python_version](https://img.shields.io/badge/Python-3.10%2B-green.svg)
[![torch_version](https://img.shields.io/badge/torch-2.0%2B-pink.svg)](requirements.txt)


## Introduction
ä¸€ä¸ªåŸºäºğŸ¤—[HuggingFace](https://huggingface.co/)å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒã€æµ‹è¯•å·¥å…·ã€‚æ”¯æŒä¸åŒæ¨¡å‹çš„webuiã€ç»ˆç«¯é¢„æµ‹ï¼Œæ”¯æŒå„æ¨¡å‹çš„ä½å‚æ•°é‡åŠå…¨å‚æ•°æ¨¡å‹çš„é¢„è®­ç»ƒã€å¥–åŠ±æ¨¡å‹è®­ç»ƒä»¥åŠRLHFè®­ç»ƒ(PPOå’ŒDPOä¸¤ç§æ–¹æ³•)ã€‚åŒæ—¶æ”¯æŒdeepspeedåˆ†å¸ƒå¼è®­ç»ƒã€‚  

ä½œè€…ä¹ æƒ¯äºæŠŠé…ç½®å’Œè¦åšçš„äº‹æƒ…éƒ½å†™åœ¨ä¸€ä¸ªé…ç½®æ–‡ä»¶é‡Œé¢ï¼Œç„¶åä»¥ä¸€ä¸ªä¸»å‡½æ•°ä½œä¸ºå…¥å£ç›´æ¥è¿è¡Œï¼Œæ‰€ä»¥æ‰æœ‰äº†è¿™ä¸ªé¡¹ç›®ï¼Œå–œæ¬¢æŒ‡ä»¤çš„æœ‹å‹ä»¬å¯ä»¥æ”¹å›å»ä½¿ç”¨ã€‚  


## Updates
Date| Detail
:---|---
2023-10-30|é€šè¿‡attention_sinksæ”¯æŒ[StreamingLLM](https://arxiv.org/abs/2309.17453)
2023-10-25|åŸºäºsentencepieceå®ç°è¯è¡¨æ‰©å……åŠŸèƒ½
2023-10-24|æ”¯æŒä½¿ç”¨[NEFTune](https://arxiv.org/abs/2310.05914)å¯¹LLMè¿›è¡Œnoise tune
2023-10-09|å¢åŠ æ‰©å……è¯è¡¨åEmbeddingåˆå§‹åŒ–æ–¹å¼
2023-10-08|LLamaå’ŒFalconä¸¤ç±»æ¨¡å‹æ”¯æŒFlash Attention2
2023-09-26|æ”¯æŒæ¨¡å‹é¢„è®­ç»ƒ
2023-09-11|å¤šè½®å¯¹è¯çš„[Fireflyçš„loss](https://mp.weixin.qq.com/s/nhogoWnzl3nrs_77r38_UA)è®­ç»ƒå‡½æ•°é›†æˆ
2023-09-04|æ”¯æŒéƒ¨åˆ†å¯ä»¥ä»é…ç½®ä¿®æ”¹ä½¿ç”¨NTKçš„æ¨¡å‹
2023-08-24|æ”¯æŒdeepspeed-ZeRo2åˆ†å¸ƒå¼è®­ç»ƒ
2023-08-23|RLHFçš„DPOæ–¹æ³•å¯¹å„ä¸ªæ¨¡å‹çš„è®­ç»ƒæ”¯æŒ
2023-08-21|RLHFçš„PPOæ–¹æ³•å¯¹å„ä¸ªæ¨¡å‹çš„è®­ç»ƒæ”¯æŒ
2023-08-08|å¥–åŠ±æ¨¡å‹è®­ç»ƒ
2023-07-25|åˆå§‹ä»“åº“

## Requirement
å‡ ä¸ªé‡è¦ç¯å¢ƒï¼š
* pythonï¼š3.10+  
* torchï¼š2.0.1+  
* bitsandbytesï¼šä¸åŒæ“ä½œç³»ç»Ÿä¸‹éœ€è¦å¯¹åº”å®‰è£…ä¸åŒçš„åŒ…ï¼ˆLinuxä¸‹0.39.0+ï¼ŒWindowsä¸‹è¦ä¸“é—¨ä¸‹è½½å¯¹åº”çš„wheelæœ¬åœ°å®‰è£…ï¼‰

å…¶å®ƒç¯å¢ƒè§requirements.txt  
ç›®å‰FlashAttentionä½œè€…æœªä¸»åŠ¨å…¼å®¹å’Œæµ‹è¯•Windowsæ“ä½œç¯å¢ƒ[issues](https://github.com/Dao-AILab/flash-attention/issues/565)ï¼Œè‹¥åœ¨Windowsä¸Šä¸ç”¨å®‰è£…flash-attnè¿™ä¸ªåŒ…ã€‚

## Feature

### Supported models
å¤§æ¨¡å‹ç»è¿‡SFT(ç„¶ååšRLHF)ä¹‹åå¯ç”¨äºå¯¹è¯ä»»åŠ¡Chatï¼Œé¢ä¸–çš„Chatå¤§éƒ¨åˆ†éƒ½æ²¡æœ‰é‡æ–°è®­ç»ƒåŸºåº§ï¼Œæˆ–è€…æ˜¯åŸºäºåŒæ ·çš„åŸºåº§ç»“æ„ç”¨æ•°æ®é‡æ–°é¢„è®­ç»ƒäº†ä¸€ä¸ªåŸºåº§ï¼Œä¸‹è¡¨æ˜¯éªŒè¯è¿‡çš„è¢«æ­¤é¡¹ç›®æ”¯æŒçš„åŸºåº§ï¼Œç›¸åº”çš„ä¹Ÿæ”¯æŒåŒæ ·ç»“æ„çš„è¡ç”Ÿå’ŒChatæ¨¡å‹ã€‚

Model    | Scale        | Series
:--------|--------------|--------
ChatGLM1 | 6B           |[chatglm1](https://huggingface.co/THUDM/chatglm-6b)
ChatGLM2 | 6B           |[chatglm2](https://huggingface.co/THUDM/chatglm2-6b)
ChatGLM3 | 6B           |[chatglm3](https://huggingface.co/THUDM/chatglm3-6b)
Qwen     | 1.8Bã€7Bã€14B |[Qwen](https://huggingface.co/Qwen)
Bloom    | 560Mã€9Bã€7B1M|[bloom](https://huggingface.co/bigscience/bloom)ã€[bloomz](https://huggingface.co/bigscience/bloomz)
LLama1   | 3Bã€7Bã€13B   |[openllama](https://huggingface.co/openlm-research)ã€[chinese-alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)ã€[ziya](https://huggingface.co/IDEA-CCNL)
LLama2   | 7Bã€13B      |[llama2](https://huggingface.co/meta-llama)ã€[orca-2](https://huggingface.co/microsoft/Orca-2-7b)
Baichuan | 7Bã€13B      |[baichuan](https://huggingface.co/baichuan-inc)
Baichuan2| 7Bã€13B      |[baichuan2](https://huggingface.co/baichuan-inc)
Falcon   | 7B           |[falcon](https://huggingface.co/tiiuae/falcon-7b)ã€[Orca-2](https://huggingface.co/Linly-AI)
Aquila   | 7B           |[aquila](https://huggingface.co/BAAI)
Aquila2  | 7B           |[aquila](https://huggingface.co/BAAI)
InternLM | 7Bã€20B      |[internlm](https://huggingface.co/internlm)
MOSS     | 16B          |[MOSS](https://huggingface.co/fnlp)
XVERSE   | 13B          |[XVERSE](https://huggingface.co/xverse/XVERSE-13B-Chat)
Mistral  | 7B           |[Mistral](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
Yi       | 6B           |[Yi](https://huggingface.co/01-ai/Yi-6B-Chat)

* æœªè¿›å…¥ä¸Šè¡¨çš„æ¨¡å‹æˆ–å‚æ•°è§„æ¨¡æš‚æ—¶æ²¡æœ‰ä½¿ç”¨è¯¥é¡¹ç›®æµ‹è¯•è¿‡ã€‚

### Template Prompt
å› ä¸ºå¾ˆå¤šè®­ç»ƒè€…éƒ½æ˜¯åŸºäºä¸Šè¿°çš„åŸºåº§æ¨¡å‹æˆ–è€…Chatæ¨¡å‹ç»§ç»­è®­ç»ƒï¼Œä½†æ˜¯å®ƒä»¬é‡‡ç”¨äº†ä¸åŒçš„template promptï¼Œæ‰€ä»¥ä¸‹è½½ç›¸å…³çš„æ¨¡å‹åï¼Œéœ€è¦æ ¹æ®è¿™äº›æ¨¡å‹çš„è¦æ±‚æ–°åŠ å…¥å’Œå®ƒä»¬ç›¸é€‚é…çš„template promptï¼Œé™¤äº†åŠ è½½è¿™äº›æ¨¡å‹å®˜æ–¹éœ€è¦çš„template promptå¤–ï¼Œæœ¬é¡¹ç›®è¿˜ç»™äº†ä¸€äº›template promptï¼Œæ¯”å¦‚ziyaã€openbuddyç­‰ç­‰çš„æ¨¡æ¿ã€‚  

Template Prompt|Website
:--------------|---------
chatglm        | [chatglm2](https://huggingface.co/THUDM/chatglm2-6b)  
chatglm3       | [chatglm3](https://huggingface.co/THUDM/chatglm3-6b)  
alpaca         | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
vicuna         | [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna)
belle          | [BELLE](https://github.com/LianjiaTech/BELLE)
ziya           | [Ziya](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)
aquila         | [AquilaChat](https://huggingface.co/BAAI/AquilaChat-7B)
firefly        | [Firefly](https://github.com/yangjianxin1/Firefly)
openbuddy      | [OpenBuddy](https://huggingface.co/OpenBuddy)
internlm       | [Internlm](https://huggingface.co/internlm)
baichuan       | [Baichuan](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat)
baichuan2      | [Baichuan2](https://github.com/baichuan-inc/Baichuan2)
qwen           | [Qwen](https://github.com/QwenLM/Qwen-7B)
moss           | [MOSS](https://github.com/OpenLMLab/MOSS)
linksoul       | [LinkSoul](https://huggingface.co/LinkSoul)
xverse         | [XVERSE](https://huggingface.co/xverse/XVERSE-13B-Chat)
tigerbot       | [TigerBot](https://github.com/TigerResearch/TigerBot)
flagalpha      | [FlagAlpha](https://github.com/FlagAlpha/Llama2-Chinese)
orca-2         | [Orca-2](https://huggingface.co/microsoft/Orca-2-7b)
yi             | [yi](https://huggingface.co/01-ai/Yi-6B-Chat)

### Training methods  

Method        |Supported| 
:-------------|---------|
Full Parameter| âœ…     |
Lora          | âœ…     |
AdaLora       | âœ…     |
QLora         | âœ…     |
Prompt Tuning | âœ…     |
P Tuning      | âœ…     |
Prefix Tuning | âœ…     |

* ä½¿ç”¨Loraå’ŒAdaLoraéƒ½æ”¯æŒQLoraè®­ç»ƒï¼Œä½†æ˜¯é‡åŒ–æ–¹å¼éœ€è¦é€‰æ‹©åŸºäºbitsandbytesçš„bnbé‡åŒ–æ–¹å¼ï¼Œå¯æ”¯æŒ4bitå’Œ8bité‡åŒ–è®­ç»ƒã€‚ä»¥ä¸‹æ˜¯å¼€å¯Qloraè®­ç»ƒçš„æ˜¯å¿…è¦é…ç½®å‚æ•°ï¼ˆModelArgumentsä¸­ï¼‰ï¼š
```
quantization: Optional[str] = field(
    default='bnb',
    metadata={
        # å¦‚æœä½¿ç”¨qloraåªèƒ½é€‰æ‹©bnbï¼Œä¸¤ç§é‡åŒ–æ–¹å¼åŒºåˆ«ä¸å¤§ã€‚
        'help': 'The specific model version to use (can be a branch name, tag name or commit id).',
        'choices': ['cpm', 'bnb'],
    }
)
quantization_bit: Optional[int] = field(
    default=None,
    metadata={
        # ä½¿ç”¨8bité‡åŒ–è¿˜æ˜¯4bité‡åŒ–ï¼Ÿ
        'help': 'The number of bits to quantize the model.',
        'choices': [4, 8],
    }
)
```

### Quantization

ä¸¤ç§é‡åŒ–æ–¹å¼åˆ†åˆ«ä¸ºåŸºäºbitsandbytesçš„bnbå’Œcpm_kernelsç»„ä»¶çš„cpmï¼Œå…¶ä¸­cpmé‡åŒ–è„šæœ¬æ¥è‡ª[quantization.py](https://huggingface.co/THUDM/chatglm2-6b/blob/main/quantization.py)ã€‚

### Metric
ä¸åŒè®­ç»ƒé˜¶æ®µè·‘æµ‹è¯•é›†æ—¶ä¼šè¾“å‡ºä¸‹é¢ä¸€äº›å¸¸è§„çš„ç”Ÿæˆæ¨¡å‹è¯„ä¼°ç»“æœï¼Œç»“æœä»…é™å‚è€ƒï¼Œå¤§æ¨¡å‹çš„äº‹å®æ€§è¯„ä¼°ç›®å‰æ²¡æœ‰æ›´å¥½çš„åŠæ³•ï¼Œéƒ½æ˜¯å„ä¸ªæ¨¡å‹å‡ºå“æ–¹æˆ–è¯„æµ‹æœºæ„åœ¨å„ç»´åº¦ä¸Šåˆ¶ä½œæ•°æ®é›†åšè¯„æµ‹ï¼Œç›¸å¯¹æ¯”è¾ƒä¸»è§‚ã€‚   

Metric  |Supported| Training Stage      |
:-------|---------|---------------------|
Rouge-1 | âœ…     |SFT Training          |
Rouge-2 | âœ…     |SFT Training          |
Rouge-l | âœ…     |SFT Training          |
ppl     | âœ…     |Pretrainã€SFT Training|
accuracy| âœ…     |PPO-RM Training       |

## Getting start
å¼€å§‹ä¹‹å‰ï¼Œéœ€è¦ç¡®å®šè¯•éªŒçš„æ¨¡å‹ï¼Œå¹¶æŠŠæ•´ä¸ªæ¨¡å‹æ–‡ä»¶ä»huggingfaceä¸Šä¸‹è½½ä¸‹æ¥ï¼Œå®Œæˆä¸¤æ­¥ï¼š
1. åœ¨ModelArgumentsä¸­é…ç½®å¥½model_typeå’Œmodel_pathä¸¤ä¸ªå‚æ•°ï¼Œå¦‚æœé™¤äº†model_pathçš„åŸºåº§æ¨¡å‹å¤–è¿˜æœ‰adapteræ¨¡å‹ï¼Œåˆ™éœ€å°†adapteræ¨¡å‹çš„åœ°å€é…ç½®åˆ°checkpoint_dirä¸­ã€‚

```
model_type: str = field(
    default='internlm',
    metadata={
        # æ¨¡å‹ç±»å‹
        'help': 'Model type.',
        'choices': ['chatglm', 'qwen', 'llama', 'falcon', 'baichuan', 'aquila', 'internlm', 'moss', 'bloom', 'rwkv'],
    }
)
model_path: str = field(
    default='/home/XXXXX/llm_models/internLM/intern-chat-7b',
    metadata={
        # ä»huggingface.co/modelsä¸Šä¸‹è½½çš„æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„è·¯å¾„ã€‚
        'help': 'Local path to pretrained model or model identifier from huggingface.co/models.'
    }
)
checkpoint_dir: Optional[str] = field(
    default=None,
    metadata={
        # ä¿å­˜ä¸‹è½½çš„æˆ–è€…è‡ªå·±è®­ç»ƒçš„adapterå¢é‡æ¨¡å‹çš„åœ°æ–¹ã€‚
        'help': 'Path to save the (delta) model checkpoints as well as the configurations automatically.',
    }
)
```
2. åœ¨DataTrainingArgumentsä¸­ä¿®æ”¹prompt_templateä½¿ç”¨å’Œè¯¥æ¨¡å‹é…å¥—çš„templateï¼Œè¿™ä¸ªtemplateä¸€èˆ¬æ˜¯SFTä¹‹åçš„æ¨¡å‹æ‰ä¼šæœ‰ï¼Œä¸”ä¸è®­ç»ƒè€…æœ‰å…³ã€‚æ‰€ä»¥å¦‚æœè¯¥é¡¹ç›®æœªæä¾›çš„ï¼Œåˆ™éœ€è¦è‡ªå·±ä¿®æ”¹engines/utils/prompt_template.pyæ–‡ä»¶ï¼Œæ·»åŠ æ–°çš„templateã€‚
```
prompt_template: Optional[str] = field(
    default='internlm',
    metadata={
        # é€‰æ‹©å¯¹åº”æ¨¡å‹çš„æ¨¡æ¿promptï¼Œä¸€èˆ¬Chatæ¨¡å‹çš„å‡ºå“æ–¹éƒ½ä¼šæœ‰ä¸€ä¸ªå›ºå®šçš„promptã€‚
        'help': 'Which template to use for constructing prompts in training and inference.'
    }
)
```

### Inference  
æ­¤å¤„æä¾›ä¸¤ç§é¢„æµ‹æ–¹å¼ï¼Œåˆ†åˆ«æ˜¯åŸºäºgradioçš„webUIé¢„æµ‹å’Œç»ˆç«¯é¢„æµ‹ã€‚éœ€è¦åœ¨config.pyä¸­å¯¹åº”ä¿®æ”¹modeï¼Œç„¶åè¿è¡Œmain.pyã€‚  

Mode              | Inference Type | 
:-----------------|----------------|
web_inference     | WebUI          |
terminal_inference| Trminal        |

* é¢„æµ‹çš„æ—¶å€™ï¼Œæ¨¡å‹ä¼šä¼˜å…ˆä»ä½ å®šä¹‰çš„ModelArgumentsä¸­çš„checkpoint_dirè¯»å–ï¼Œå¦‚æœè¯¥æ–‡ä»¶ä¸‹æ²¡æœ‰å‚æ•°æ–‡ä»¶ï¼Œåˆ™ä»TrainingArgumentsçš„output_diræ–‡ä»¶å¤¹åŠ è½½ï¼Œå¦‚æœéƒ½æ²¡æœ‰åˆ™åªåŠ è½½æœ€åˆçš„åŸºåº§æ¨¡å‹ã€‚

#### NTK
ç›®å‰åŸç”Ÿçš„configå°±èƒ½æ”¯æŒNTKæ–¹æ³•çš„æœ‰[chatglm2-6b-32k](https://huggingface.co/THUDM/chatglm2-6b-32k)ã€LLamaç³»åˆ—ã€Falconç³»åˆ—å’Œ[Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat)ï¼š  

Model          |Position Encoder|Support NTK Type| 
:--------------|----------------|----------------|
chatglm2-6b-32k| Rope           |  Linear        |
Qwen-7B-Chat   | Rope           | Dynamic        |
LLamaç³»åˆ—      | Rope            |Dynamicã€Linear |
Falconç³»åˆ—     | Rope           |Dynamicã€Linear |

* å…¶ä»–çš„æ¨¡å‹éœ€è¦è‡ªå·±æ›´æ”¹åŸå§‹çš„æ¨¡å‹æ–‡ä»¶å»æ”¯æŒNTKæ–¹æ³•ï¼Œæ¯”å¦‚å¯ç”¨äºAlibiç¼–ç çš„æ¨¡å‹Baichuanã€Falconã€Bloomç³»åˆ—çš„[NTK-ALibi](https://github.com/keezen/ntk_alibi)ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒNTKä¸»è¦ç”¨åœ¨æ¨æ–­çš„æ—¶å€™çªç ´æ¨¡å‹çš„è¾“å…¥tokené™åˆ¶ï¼Œä½†æ˜¯è®­ç»ƒçš„æ—¶å€™æ‰“å¼€NTKå¯èƒ½ä¼šå¾—ä¸åˆ°æƒ³è¦çš„æ•ˆæœã€‚
* Falconç³»åˆ—çš„æ¨¡å‹HFå®˜æ–¹æä¾›äº†ä¸¤ç§ç¼–ç æ–¹å¼ï¼Œåˆ†åˆ«æ˜¯Ropeå’ŒAlibiï¼Œä½†æ˜¯tiiuaeå®˜æ–¹ç›®å‰åªæœ‰Alibiçš„å®ç°ï¼Œä¸çŸ¥é“æ­¤ä¸¾ä¸ºä½•ï¼Œæ‰€ä»¥æ­¤å¤„ä»…æ”¯æŒä½¿ç”¨Ropeç¼–ç æ–¹å¼çš„NTKæ–¹æ³•ã€‚

## Train

### Pretrain
é¢„è®­ç»ƒæ•°æ®å‚è€ƒdatasets/pretrain/example/trainä¸‹é¢çš„æ–‡ä»¶ï¼Œæ•°æ®ä¸ºtxtæ ¼å¼å­˜å‚¨ï¼Œåˆ¶ä½œæ•°æ®é›†æœ€å¥½èƒ½å¤Ÿå‘ä¾‹å­ç»™çš„ä¸€æ ·ï¼Œä¸€è¡Œä¸ºä¸€å¥è¯ï¼Œä½†æ˜¯æœ€å¥½ä¸å¤§äºæ¨¡å‹æ¥æ”¶çš„æœ€å¤§tokené•¿åº¦ã€‚ç„¶åæŠŠæ•°æ®è·¯å¾„å¡«å†™åˆ°DataTrainingArgumentsé…ç½®é‡Œé¢ï¼š
```
train_file_dir: Optional[str] = field(
    default='datasets/pretrain/example/train',
    metadata={
        # è®­ç»ƒé›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The train json data file folder.'
    }
)
validation_file_dir: Optional[str] = field(
    default='datasets/pretrain/example/train',
    metadata={
        # éªŒè¯é›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The evaluation json file folder.'
    }
)
```
å¼€å¯è®­ç»ƒçš„æ—¶å€™ï¼Œéœ€è¦åœ¨config.pyä¸­å°†modeä¿®æ”¹ä¸º**pretrain**ï¼Œç„¶åè¿è¡Œmain.pyã€‚

### SFT training

æŒ‡ä»¤å¾®è°ƒæ•°æ®å‚è€ƒdatasets/finetune/example/trainä¸‹é¢çš„æ–‡ä»¶ï¼Œæ•°æ®ç”±instructionã€inputã€outputå’Œhistoryå››ä¸ªå­—æ®µç»„æˆã€‚
```
[
  {
    "instruction": "10ä¹˜ä»¥10ç­‰äºå¤šå°‘ï¼Ÿ",
    "input": "",
    "output": "10ä¹˜ä»¥10ç­‰äº100ã€‚",
    "history": [
        "ä½ å¥½å‘€ã€‚",
        "ä½ å¥½ï¼Œè¯·é—®æ‚¨æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ",
        "å¥½çš„ï¼Œæˆ‘æƒ³é—®ä¸‹ä½ æ˜¯è°ï¼Ÿ",
        "æˆ‘æ˜¯ä¸€ä¸ªAIæ¨¡å‹ï¼Œèƒ½å¤Ÿè§£å†³ä½ æå‡ºçš„é—®é¢˜ã€‚"
      ]
  },
  ...  
]
```
å¦‚ä¸Šé¢æ‰€ç¤ºhistoryå­—æ®µéœ€è¦æŒ‰ç…§ä¸€é—®ä¸€ç­”çš„æ ¼å¼å­˜å‚¨å¯¹è¯å†å²ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒã€‚å¦‚æœæ²¡æœ‰å†å²å¯¹è¯éœ€è¦è®©historyä¸ºç©ºåˆ—è¡¨ï¼š
```
[
  {
    "instruction": "ä½ èº«ä»½æ˜¯ä»€ä¹ˆï¼Ÿ",
    "input": "",
    "output": "æˆ‘æ˜¯ä¸€ä¸ªAIæ™ºèƒ½åŠ©æ‰‹ï¼Œç”±XXå…¬å¸è®­ç»ƒï¼Œæˆ‘å°†åŠ›æ‰€èƒ½åŠçš„å¸®åŠ©ä½ è§£å†³é—®é¢˜ã€‚",
    "history": []
  },
  ...  
]
```

ä½¿ç”¨çš„æ—¶å€™æŠŠæ•°æ®è·¯å¾„å¡«å†™åˆ°DataTrainingArgumentsé…ç½®é‡Œé¢ï¼š
```
train_file_dir: Optional[str] = field(
    default='datasets/finetune/example/train',
    metadata={
        # è®­ç»ƒé›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The train json data file folder.'
    }
)
validation_file_dir: Optional[str] = field(
    default='datasets/finetune/example/eval',
    metadata={
        # éªŒè¯é›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The evaluation json file folder.'
    }
)
```

å¼€å¯è®­ç»ƒçš„æ—¶å€™ï¼Œéœ€è¦åœ¨config.pyä¸­å¯¹åº”ä¿®æ”¹modeä¸º**sft_train**ï¼Œç„¶ååœ¨TrainingArgumentsä¸­é…ç½®å¥½å„é¡¹è®­ç»ƒå‚æ•°ï¼Œç„¶åè¿è¡Œmain.pyã€‚
æ¡†æ¶æ”¯æŒæµ‹è¯•SFTè®­ç»ƒçš„æ•ˆæœï¼Œæµ‹è¯•å‰åœ¨DataTrainingArgumentsä¸­é…ç½®test_fileä¸ºæµ‹è¯•æ•°æ®é›†æ‰€åœ¨çš„è·¯å¾„ï¼Œç„¶ååœ¨config.pyä¸­å°†modeä¿®æ”¹ä¸º**sft_batch_test**ï¼Œç„¶åè¿è¡Œmain.pyã€‚  
```
test_file: Optional[str] = field(
    default='datasets/finetune/test',
    metadata={
        # æµ‹è¯•é›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The test file.'
    }
)
```

### RM training
å¥–åŠ±æ¨¡å‹è®­ç»ƒæ•°æ®å‚è€ƒdatasets/rm/example/trainä¸‹é¢çš„æ–‡ä»¶ï¼Œæ•°æ®ç”±instructionã€inputã€outputä¸‰ä¸ªå­—æ®µç»„æˆã€‚outputæ˜¯ä¸€ä¸ªä¸¤å…ƒç´ åˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯é‡‡çº³çš„ç­”æ¡ˆï¼Œç¬¬äºŒä¸ªæ˜¯æ‹’ç»çš„ç­”æ¡ˆã€‚ä½¿ç”¨çš„æ—¶å€™æŠŠè®­ç»ƒå¥–åŠ±æ¨¡å‹çš„æ•°æ®ä¸€æ ·å¡«å†™åˆ°DataTrainingArgumentsé…ç½®é‡Œé¢ã€‚ç„¶åéœ€è¦åœ¨config.pyä¸­å¯¹åº”ä¿®æ”¹modeä¸º**rm_train**ï¼Œåœ¨TrainingArgumentsä¸­é…ç½®å¥½å„é¡¹è®­ç»ƒå‚æ•°ï¼Œè¿è¡Œmain.pyã€‚
```
train_file_dir: Optional[str] = field(
    default='datasets/rm/example/train',
    metadata={
        # è®­ç»ƒé›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The train json data file folder.'
    }
)
validation_file_dir: Optional[str] = field(
    default='datasets/rm/example/eval',
    metadata={
        # éªŒè¯é›†ä¿å­˜çš„è·¯å¾„ã€‚
        'help': 'The evaluation json file folder.'
    }
)
```

æ¡†æ¶æ”¯æŒæµ‹è¯•å¥–åŠ±æ¨¡å‹è®­ç»ƒçš„æ•ˆæœï¼Œé¦–å…ˆéœ€è¦åœ¨DataTrainingArgumentsä¸­é…ç½®test_fileä¸ºæµ‹è¯•æ•°æ®é›†æ‰€åœ¨çš„è·¯å¾„ï¼Œç„¶ååœ¨config.pyä¸­å°†modeä¿®æ”¹ä¸º**rm_batch_test**ï¼Œè¿è¡Œmain.pyï¼Œå¥–åŠ±æ¨¡å‹æµ‹è¯•åªä¼šè¾“å‡ºæ¨¡å‹çš„å‡†ç¡®ç‡ã€‚

* å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸æ”¯æŒç¬¬ä¸€ä»£ChatGLM6Bï¼Œå› ä¸ºé¡¹ç›®ç”¨trlçš„AutoModelForCausalLMWithValueHeadç»„ä»¶æ˜¯åŸºäºCausalLMæ¨¡å‹çš„ã€‚ChatGLM6Bæ˜¯åŸºäºPrefix LMå®ç°çš„ã€‚

### RLHF training
#### PPO
åœ¨è¿›è¡ŒåŸºäºPPOæ¨¡å‹çš„RLHFè®­ç»ƒä¹‹å‰ï¼Œéœ€è¦ä¸€ä¸ªå¥–åŠ±æ¨¡å‹å’Œä¸€ä¸ªéœ€è¦è¢«RLHFå¾®è°ƒçš„SFTæ¨¡å‹ï¼Œéœ€è¦æŠŠä»–ä»¬é…ç½®åˆ°ModelArgumentsä¸­å¦‚ä¸‹ï¼š
```
checkpoint_dir: Optional[str] = field(
    default='checkpoint/sft',
    metadata={
        # ä¿å­˜ä¸‹è½½çš„æˆ–è€…è‡ªå·±è®­ç»ƒçš„adapterå¢é‡æ¨¡å‹çš„åœ°æ–¹ï¼Œåœ¨RLHFæ—¶å€™ï¼Œæ­¤å¤„éœ€è¦å¡«å†™æŒ‡ä»¤å¾®è°ƒåæ¨¡å‹æ‰€åœ¨çš„æ–‡ä»¶åœ°å€ã€‚
        'help': 'Path to save the (delta) model checkpoints as well as the configurations automatically.',
    }
)
reward_model_checkpoint: str = field(
    default='checkpoint/rm',
    metadata={
        # åœ¨RLHFæ—¶å€™ï¼Œæ­¤å¤„éœ€è¦å¡«å†™å¥–åŠ±æ¨¡å‹æ‰€åœ¨çš„æ–‡ä»¶åœ°å€
        'help': 'The checkpoint of reward model.'
    }
)
```
PPOæ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ•°æ®å’ŒSFTé˜¶æ®µè®­ç»ƒçš„æ•°æ®çš„æ ¼å¼æ˜¯ä¸€è‡´çš„ï¼Œæ­¤å¤–ä½¿ç”¨çš„æ—¶å€™è¿˜éœ€è¦åœ¨TrainingArgumentsä¸­æŠŠPPOçš„é…ç½®å¡«å†™å¥½ï¼Œåœ¨config.pyä¸­å°†modeä¿®æ”¹ä¸ºppo_trainï¼Œç„¶åè¿è¡Œmain.pyã€‚è®­ç»ƒçš„ç»“æœå°†ä¼šé€šè¿‡wandbçš„æ ¼å¼è®°å½•åœ¨è®­ç»ƒè¾“å‡ºçš„æ–‡ä»¶å¤¹ä¸­ã€‚

#### DPO
åœ¨è¿›è¡ŒåŸºäºDPOæ¨¡å‹çš„RLHFè®­ç»ƒä¹‹å‰ï¼Œåªéœ€è¦ä¸€ä¸ªè¢«RLHFå¾®è°ƒçš„SFTæ¨¡å‹ï¼Œå¦‚æœæ˜¯åŸºäºadapterçš„æ¨¡å‹è¿˜éœ€è¦æŠŠadapteré…ç½®åˆ°ModelArgumentsä¸­å¦‚ä¸‹ï¼š
```
model_path: str = field(
    default='/home/XXX/ChatGLM/ChatGLM2-6B-32k',
    metadata={
        # ä»huggingface.co/modelsä¸Šä¸‹è½½çš„æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„è·¯å¾„æˆ–è€…è‡ªå·±çš„æ¨¡å‹ã€‚
        'help': 'Local path to pretrained model or model identifier from huggingface.co/models.'
    }
)
checkpoint_dir: Optional[str] = field(
    default='checkpoint/sft',
    metadata={
        # ä¿å­˜ä¸‹è½½çš„æˆ–è€…è‡ªå·±è®­ç»ƒçš„adapterå¢é‡æ¨¡å‹çš„åœ°æ–¹ï¼Œåœ¨RLHFæ—¶å€™ï¼Œæ­¤å¤„éœ€è¦å¡«å†™æŒ‡ä»¤å¾®è°ƒåæ¨¡å‹æ‰€åœ¨çš„æ–‡ä»¶åœ°å€ã€‚
        'help': 'Path to save the (delta) model checkpoints as well as the configurations automatically.',
    }
)
```
DPOæ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ•°æ®å’Œå¥–åŠ±æ¨¡å‹çš„æ•°æ®æ˜¯ä¸€è‡´çš„ï¼Œåœ¨config.pyä¸­å°†modeä¿®æ”¹ä¸ºdpo_trainï¼Œç„¶åè¿è¡Œmain.pyã€‚è®­ç»ƒçš„ç»“æœå°†ä¼šé€šè¿‡wandbçš„æ ¼å¼è®°å½•åœ¨è®­ç»ƒè¾“å‡ºçš„æ–‡ä»¶å¤¹ä¸­ã€‚

* å¦‚æœå‰é¢ä½¿ç”¨çš„æ˜¯adapteråœ¨SFTæ¨¡å‹ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼ŒRLHFçš„æ—¶å€™é¡¹ç›®ä¼šèåˆå‰é¢çš„adapterååˆ›å»ºæ–°çš„adapterç»§ç»­è®­ç»ƒã€‚

### Training Arguments  
å¸¸ç”¨çš„ä¸€äº›å‚æ•°å¦‚ä¸‹ï¼š

Arguments                    | Describe                | 
:----------------------------|-------------------------|
fine_tuning_type             | è®­ç»ƒæ–¹å¼                 |
use_firefly_loss             | ä½¿ç”¨Firefly lossè®­ç»ƒæ¨¡å‹ |
output_dir                   | è®­ç»ƒç»“æœè¾“å‡ºçš„æ–‡ä»¶å¤¹      |
num_train_epochs             | è®­ç»ƒçš„è½®æ¬¡               |
gradient_accumulation_steps  | æ¢¯åº¦ç´¯ç§¯                 |
per_device_train_batch_size  | æ¯ä¸ªè®¾å¤‡ä¸Šçš„æ‰¹å¤§å°        |
learning_rate                | å­¦ä¹ ç‡                   |
fp16                         | è®¾ç½®Trueä¸ºå¼€æ··åˆç²¾åº¦è¿ç®—  |


* Loraå’Œå…¶å®ƒadapterè®­ç»ƒæ–¹å¼çš„é…ç½®å‚æ•°ä¹Ÿåœ¨TrainingArgumentsä¸­ï¼Œè¿™é‡Œé¢è¦æ³¨æ„lora_targetçš„è®¾ç½®è¦æ ¹æ®è‡ªå·±çš„æ¨¡å‹ç»“æ„æ¥ï¼Œé…ç½®ä¸­ç»™äº†ä¸€äº›å‚è€ƒã€‚
* Firefly Lossä»…ä½œç”¨åœ¨SFTè®­ç»ƒé˜¶æ®µä¸”ä¸æ”¯æŒChatGLM6Bç­‰Prefix LMæ¨¡å‹ã€‚

### DeepSpeed
ä½¿ç”¨deepspeedè¿›è¡Œè®­ç»ƒéœ€è¦åœ¨TrainingArgumentsæŒ‡å®šdeepspeedçš„configæ–‡ä»¶(é¡¹ç›®ä¸­æä¾›äº†stage2çš„deepspeedé…ç½®)ï¼š
```
deepspeed: Optional[str] = field(
    default='deepspeed_configs/zero_stage2_config.json',
    metadata={
        'help': 'Enable deepspeed and pass the path to deepspeed json config file (e.g. ds_config.json) '
                'or an already loaded json file as a dict'
    }
)
```
é…ç½®å¥½ååœ¨ç»ˆç«¯è¾“å…¥(å•æœºå¤šå¡)ï¼š
```
deepspeed --num_gpus 3 --master_port=9901 main.py
```

* å¤šæœºå¤šå¡éœ€è¦æŒ‡å®šæ›´å¤šçš„å‚æ•°ï¼Œå¯ä»¥å‚è€ƒhugingfaceçš„deepspeedæ–‡æ¡£ã€‚

## Others
 Mode                 | Describe                                                     
 :------------------- | ------------------------------------------------------------ 
 merge_lora_model     | å°†loraæ¨¡å‹å’ŒåŸºåº§æ¨¡å‹èåˆï¼Œæ”¯æŒloraå’Œadaloraä¹‹åçš„æƒé‡åˆå¹¶ï¼Œå…¶å®ƒçš„è®­ç»ƒæ–¹æ³•äº§ç”Ÿçš„adapterç›´æ¥é€šè¿‡peftåŠ è½½å³å¯ï¼Œä¸æ”¯æŒåˆå¹¶ 
 show_model_info      | æ‰“å°æ¨¡å‹çš„ç»“æ„å’Œæ¨¡å‹çš„å‚æ•°                                   
 save_quantized_model | é‡åŒ–å¹¶ä¿å­˜é‡åŒ–æ¨¡å‹                                           
 expand_vocab         | æ ¹æ®ç»™å®šè¯­æ–™æ‰©å……è¯è¡¨ï¼ˆå¦‚æ‰©å……ä¸­æ–‡è¯è¡¨ã€å‚åŸŸè¯è¡¨ç­‰ï¼‰           

* merge_peft_modelå’Œsave_quantized_modeléœ€è¦åœ¨ModelArgumentsè®¾ç½®è¾“å‡ºåœ°å€ã€‚
```
quantized_or_merged_output_dir: Optional[str] = field(
    default=None,
    metadata={
        # å½“ä½ æƒ³ä¿å­˜é‡åŒ–åçš„æ¨¡å‹æˆ–è€…èåˆåçš„æ¨¡å‹æ—¶ï¼Œå¤„ç†åçš„æ¨¡å‹ä¿å­˜çš„åœ°å€ã€‚
        'help': 'Path to save the quantized or merged model checkpoints as well as the configurations manually.',
    }
)
```
* ä½¿ç”¨bnbå’Œcpmé‡åŒ–å°†ä¼šé»˜è®¤å¯¹é™¤äº†è¾“å‡ºå±‚çš„æ‰€æœ‰çº¿æ€§å±‚è¿›è¡Œé‡åŒ–ã€‚
* ä½¿ç”¨expand_vocabæ–¹æ³•è¿›è¡Œè¯è¡¨æ‰©å……æ—¶ï¼Œéœ€è¦æŒ‡å®šè®­ç»ƒè¯è¡¨çš„è¯­æ–™è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹å‡å¯ï¼‰ã€‚ä»…æ”¯æŒ `.txt` ä¸ `.tsv` æ ¼å¼ã€‚è¯è¡¨æ‰©å……åï¼Œä¸€èˆ¬éœ€è¦ç»§ç»­é¢„è®­ç»ƒã€‚

## Todo
- [x] å¥–åŠ±æ¨¡å‹è®­ç»ƒ
- [x] PPOæ¨¡å‹è®­ç»ƒ
- [x] DPOæ¨¡å‹è®­ç»ƒ
- [x] æ”¯æŒDeepspeedè®­ç»ƒ
- [x] [NTK-Aware Scaled RoPE](https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/?rdt=35901)é›†æˆ
- [x] å¤šè½®å¯¹è¯çš„[Fireflyçš„loss](https://mp.weixin.qq.com/s/nhogoWnzl3nrs_77r38_UA)å‡½æ•°é›†æˆ
- [x] æ”¯æŒLLMå¢é‡é¢„è®­ç»ƒ
- [x] å¯¹LLamaå’ŒFalconå¢åŠ Flash Attention2
- [ ] mmluã€cmmluå’ŒC-Evalè‡ªåŠ¨åŒ–è¯„ä¼°


## Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†è¯¥é¡¹ç›®ï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```latex
@misc{LLMs Tool,
  title={LLMs Tool: a tool for large language models},
  author={Shouxian Li},
  year={2023},
  howpublished={\url{https://github.com/stanleylsx/llms_tool}},
}
```

## Star History

![Star History Chart](https://api.star-history.com/svg?repos=stanleylsx/llms_tool&type=Date)
